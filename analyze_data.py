import pandas as pd
import numpy as np
import warnings

warnings.filterwarnings("ignore")

train_file = '/home/kg/train.csv'
test_file = '/home/kg/test.csv'

train_file_path = '/home/kg/train/train1.csv'
test_file_path = '/home/kg/test/test1.csv'


##把大csv文件切分为几个小csv文件方便进行存储读取等
def split_csv(file):
    data = pd.read_csv(file, header=0)
    head = data.columns
    rownum = data.shape[0]
    colnum = data.shape[1]
    slidenum = 1000000
    start = 0
    end = 1000000
    filenum = 1
    while start < rownum:
        if end <= colnum:
            tmpdata = pd.DataFrame(data.iloc[start:end, :])
            tmpdata.to_csv('train%d.csv' % filenum, header=head, index=False)
        else:
            tmpdata = pd.DataFrame(data.iloc[start:end, :])
            tmpdata.to_csv('train%d.csv' % filenum, header=head, index=False)
        print("%d file has done!" % filenum)
        filenum += 1
        start = end
        end += slidenum


##对csv大文件进行抽样存储
def sample_data(file):
    data = pd.read_csv(file)
    print("file read done!")
    print("There are %d columns and %d rows in total" % (data.shape[1], data.shape[0]))
    head = data.columns  # 头部信息
    sam_data = data.iloc[2, :].values.reshape((1, data.shape[1]))
    for i in range(data.shape[0]):
        if i % 10000 == 0:
            tmp = data.iloc[i, :].values.reshape((1, data.shape[1]))
            sam_data = np.concatenate([sam_data, tmp], axis=0)
            print("%0.2f%% lines has done!" % (i / data.shape[0] * 100))
    sam_data = pd.DataFrame(sam_data)
    sam_data.to_csv('/home/kg/sample_train.csv', index=False, header=head)


def encode(data_file):
    from sklearn.preprocessing import LabelEncoder
    data = pd.read_csv(data_file, header=0)
    head = data.columns
    print("file read done!")
    dtrain = data.iloc[:, :-1]
    label = data.iloc[:, -1]
    lenc = LabelEncoder()
    lenc.fit(label)
    label = lenc.transform(label)
    for i in range(dtrain.shape[1]):
        if data.dtypes[i] == 'object':
            dtrain.iloc[:, i].fillna('abnormal', inplace=True)
        else:
            # dtrain.iloc[:, i].fillna(-1, inplace=True)
            dtrain.iloc[:, i][np.isnan(dtrain.iloc[:, i])] = -1
            dtrain.iloc[:, i][np.isinf(dtrain.iloc[:, i])] = -2
    print("fill nan over!")
    vec = pd.DataFrame()
    for i in range(dtrain.shape[1]):
        print(i)
        enc = LabelEncoder()
        enc.fit(dtrain.iloc[:, i])
        res = pd.DataFrame(enc.transform(dtrain.iloc[:, i]))
        vec = pd.concat([vec, res], axis=1)
    vec.columns = [data.columns[:-1]]   ##对vec进行head 重命名
    return vec, label


def detect_modle():
    from sklearn.model_selection import train_test_split
    from sklearn import metrics
    from xgboost import XGBClassifier

    X, label = encode(train_file_path)
    train_x, test_x, train_y, test_y = train_test_split(X, label, test_size=0.3)
    xgbclf = XGBClassifier(n_jobs=-1)
    xgbclf.fit(train_x, train_y)
    xgbpre = xgbclf.predict(test_x)
    xgb_report = metrics.classification_report(test_y, xgbpre)
    print(xgb_report)


if __name__ == '__main__':
    # sample_data(train_file)

    detect_modle()
