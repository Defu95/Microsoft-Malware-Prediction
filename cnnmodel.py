# -*- coding: utf-8 -*-
import numpy as np
import keras
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder
from keras.models import Model, Sequential
from keras.layers.convolutional import Conv1D, MaxPooling1D, Convolution1D
from keras.layers import Input, Flatten, Dense, Dropout, Activation
from keras.callbacks import ModelCheckpoint
from keras import optimizers
import os

# os.environ["CUDA_VISIBLE_DEVICES"] = "0"
os.environ["CUDA_VISIBLE_DEVICES"] = "1"


def conv_network():
    np.random.seed(962342)
    np.set_printoptions(threshold=np.inf)
    data1 = pd.read_csv('/home/msmal/object_type/X_enc_object.csv', header=0)
    print("data1 read over!")
    data2 = pd.read_csv('/home/msmal/float_type/train.csv', header=0)
    data2[np.isinf(data2)] = -1
    data2[np.isnan(data2)] = -2
    print("data2 read over!")
    X = pd.concat([data1.iloc[:, 1:], data2], axis=1)
    y = pd.read_csv('/home/msmal/label.csv', header=0)
    # X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=49)
    # X_train = X_train.iloc[:, :].values
    # X_test = X_test.iloc[:, :].values
    # Y_train = Y_train.iloc[:, :].values
    # Y_test = Y_test.iloc[:, :].values
    # num_classes=2

    scaler = preprocessing.StandardScaler()
    X_scaled = scaler.fit_transform(X)
    encoder = LabelEncoder()
    y = encoder.fit_transform(y)
    X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, y, test_size=0.05, random_state=49)
    dimension = data1.shape[1] + data2.shape[1] - 1
    X_train = X_train.reshape(len(Y_train), dimension)
    X_test = X_test.reshape(len(Y_test), dimension)
    X_train = X_train.reshape(X_train.shape[0], dimension, 1).astype('float32')
    X_test = X_test.reshape(X_test.shape[0], dimension, 1).astype('float32')
    num_classes = len(set(Y_train))

    Y_train = Y_train.reshape(Y_train.shape[0], 1).astype('float32')
    Y_test = Y_test.reshape(Y_test.shape[0], 1).astype('float32')
    Y_train2 = keras.utils.to_categorical(Y_train, num_classes).astype('float32')
    Y_test2 = keras.utils.to_categorical(Y_test).astype('float32')

    img_input = Input(shape=X_train.shape[1:])
    # print(img_input)
    # print(X_train.shape)
    x = Conv1D(16, 3, border_mode='same', activation='relu')(img_input)
    x = Conv1D(16, 3, border_mode='same', activation='relu')(x)
    x = MaxPooling1D(2, name='block1_pool')(x)

    # Block 2
    x = Conv1D(32, 3, border_mode='same', activation='relu', name='block2_conv1')(x)
    x = Conv1D(32, 3, border_mode='same', activation='relu', name='block2_conv2')(x)
    # x=Conv1D(32,3,border_mode='same',activation='relu',name='block2_conv3')(x)
    x = MaxPooling1D(2, name='block2_pool')(x)

    # Block 3
    x = Conv1D(64, 3, activation='relu', padding='same', name='block3_conv1')(x)
    x = Conv1D(64, 3, activation='relu', padding='same', name='block3_conv2')(x)
    # x=Conv1D(64,3,activation='relu',padding='same',name='block3_conv3')(x)
    x = MaxPooling1D(2, name='block3_pool')(x)

    # Block 4
    x = Conv1D(128, 3, activation='relu', padding='same', name='block4_conv1')(x)
    x = Conv1D(128, 3, activation='relu', padding='same', name='block4_conv2')(x)
    # x=Conv1D(128,3,activation='relu',padding='same',name='block4_conv3')(x)
    x = MaxPooling1D(2, name='block4_pool')(x)

    # Block 5
    # x=Conv1D(256,3,activation='relu',padding='same',name='block5_conv1')(x)
    # x=Conv1D(256,3,activation='relu',padding='same',name='block5_conv2')(x)
    # x=Conv1D(256,3,activation='relu',padding='same',name='block5_conv3')(x)
    # x=MaxPooling1D(2,name='block5_pool')(x)

    # Block 6
    # x=Conv1D(512,3,activation='relu',padding='same',name='block6_conv1')(x)
    # x=Conv1D(512,3,activation='relu',padding='same',name='block6_conv2')(x)
    # x=Conv1D(512,3,activation='relu',padding='same',name='block6_conv3')(x)
    # x=MaxPooling1D(2,name='block6_pool')(x)

    # Top layers
    x = Flatten(name='flatten')(x)
    # inputs = Input(shape=(224, ))
    # x = Dense(100, activation='relu')(inputs)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.4)(x)
    # x = Dense(128, activation='relu')(x)
    # x = Dropout(0.5)(x)
    # x = Dense(64, activation='relu')(x)
    # x = Dropout(0.5)(x)

    # print('numcalsses=%s'%num_classes)
    x = Dense(num_classes, activation='softmax')(x)
    # print(x)
    # model3 = Model(inputs , x)
    model3 = Model(img_input, x)

    model3.compile(loss='categorical_crossentropy', optimizer="adam", metrics=['accuracy'])
    # model3.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.Adam(lr=0.1, beta_1=0.9, beta_2=0.999), metrics=['accuracy'])
    model3.summary()
    print(X_train.shape, Y_train2.shape, X_test.shape, Y_test2.shape)

    # model3fit = model3.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=50, verbose=1, epochs=25)
    batch = 25600;
    epoch = 100
    model3.fit(X_train, Y_train2, batch_size=batch, epochs=epoch)
    score = model3.evaluate(X_test, Y_test2)
    model3.save('model.h5')
    return score


def load_model():
    import numpy as np
    import pandas as pd
    from keras.models import load_model
    from sklearn import preprocessing
    # 载入模型
    model = load_model('cnnmodel.h5')
    print("model load over!")
    data1 = pd.read_csv('/home/msmal/object_type/test_scale.csv', header=0)
    print("data1 read over!")
    data2 = pd.read_csv('/home/msmal/float_type/test.csv', header=0)
    data2[np.isinf(data2)] = -1
    data2[np.isnan(data2)] = -2
    print("data2 read over!")
    # X = pd.concat([data1.iloc[:, 1:], data2], axis=1)

    scaler = preprocessing.StandardScaler()
    data2_scaled = scaler.fit_transform(data2)
    dimension = data1.shape[1] + data2.shape[1] - 1
    test_scaled = pd.concat([data1.iloc[:, 1:], pd.DataFrame(data2_scaled)], axis=1)
    test_scaled = test_scaled.values
    x_test = test_scaled.reshape(data1.shape[0], dimension)
    x_test = x_test.reshape(x_test.shape[0], dimension, 1).astype('float32')

    preres = model.predict(x_test)
    res = np.argmax(preres, axis=1)
    res = pd.DataFrame(res)
    sample = pd.read_csv('/home/msmal/sample_submission.csv', header=0)
    sam_index = sample.iloc[:, 0]
    submit = pd.concat([pd.DataFrame(sam_index), res], axis=1)
    submit.to_csv('19-1-27submit.csv', header=sample.columns, index=False)
    # 保存参数，载入参数
    # model.save_weights('my_model_weights.h5')
    # model.load_weights('my_model_weights.h5')
    # # 保存网络结构，载入网络结构
    # from keras.models import model_from_json
    # json_string = model.to_json()
    # model = model_from_json(json_string)


def conv_network2():
    # data1 = pd.read_csv('/home/msmal/object_type/train_scale.csv', header=0)
    # print("data1 read over!")
    # data2 = pd.read_csv('/home/msmal/float_type/train_scale.csv', header=0)
    # print("data2 read over!")
    data1 = pd.read_csv('/home/msmal/object_type/train_scale.csv', header=0)
    print("data1 read over!")
    data2 = pd.read_csv('/home/msmal/float_type/train_mean.csv', header=0)
    print("data2 read over!")
    y = pd.read_csv('/home/msmal/label.csv', header=0)
    X_scaled = pd.concat([data1.iloc[:, 1:], pd.DataFrame(data2)], axis=1)
    encoder = LabelEncoder()
    y = encoder.fit_transform(y)
    dimension = data1.shape[1] + data2.shape[1] - 1
    X_scaled = X_scaled.values
    X_train = X_scaled.reshape(len(y), dimension)
    X_train = X_train.reshape(X_train.shape[0], dimension, 1).astype('float32')
    num_classes = len(set(y))
    Y_train = y.reshape(y.shape[0], 1).astype('float32')
    Y_train2 = keras.utils.to_categorical(Y_train, num_classes).astype('float32')

    img_input = Input(shape=X_train.shape[1:])
    x = Conv1D(16, 3, border_mode='same', activation='relu')(img_input)
    x = Conv1D(16, 3, border_mode='same', activation='relu')(x)
    x = MaxPooling1D(2, name='block1_pool')(x)

    # Block 2
    x = Conv1D(32, 3, border_mode='same', activation='relu', name='block2_conv1')(x)
    x = Conv1D(32, 3, border_mode='same', activation='relu', name='block2_conv2')(x)
    # x=Conv1D(32,3,border_mode='same',activation='relu',name='block2_conv3')(x)
    x = MaxPooling1D(2, name='block2_pool')(x)

    # Block 3
    x = Conv1D(64, 3, activation='relu', padding='same', name='block3_conv1')(x)
    x = Conv1D(64, 3, activation='relu', padding='same', name='block3_conv2')(x)
    # # x=Conv1D(64,3,activation='relu',padding='same',name='block3_conv3')(x)
    # x = MaxPooling1D(2, name='block3_pool')(x)

    # Top layers
    x = Flatten(name='flatten')(x)
    # inputs = Input(shape=(224, ))
    # x = Dense(100, activation='relu')(inputs)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.3)(x)
    x = Dense(num_classes, activation='softmax')(x)
    model = Model(img_input, x)
    # sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
    adam = optimizers.Adam(lr=0.5)
    adadelta = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-06)
    # model.compile(loss='categorical_crossentropy', optimizer="adam", metrics=['accuracy'])
    model.compile(loss='categorical_crossentropy', optimizer=adadelta, metrics=['accuracy'])
    filepath = "vgg-weights-{epoch:02d}-{acc:.2f}.hdf5"
    # 中途训练效果提升, 则将文件保存, 每提升一次, 保存一次
    checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, period=5,
                                 mode='max')
    callback_list = [checkpoint]
    model.summary()
    batch = 25600
    epoch = 300
    model.fit(X_train, Y_train2, batch_size=batch, epochs=epoch, callbacks=callback_list)


def load_model2():
    import os
    os.environ["CUDA_VISIBLE_DEVICES"] = "1"
    import numpy as np
    import pandas as pd
    from keras.models import load_model
    # 载入模型
    model = load_model('cnnmodel.h5')
    print("model load over!")
    data1 = pd.read_csv('/home/msmal/object_type/test_scale.csv', header=0)
    print("data1 read over!")
    data2 = pd.read_csv('/home/msmal/float_type/test_scale.csv', header=0)
    print("data2 read over!")
    dimension = data1.shape[1] + data2.shape[1] - 1
    test_scaled = pd.concat([data1.iloc[:, 1:], data2], axis=1)
    test_scaled = test_scaled.values
    x_test = test_scaled.reshape(data1.shape[0], dimension)
    x_test = x_test.reshape(x_test.shape[0], dimension, 1).astype('float32')

    preres = model.predict(x_test)
    res = np.argmax(preres, axis=1)
    res = pd.DataFrame(res)
    sample = pd.read_csv('/home/msmal/sample_submission.csv', header=0)
    sam_index = sample.iloc[:, 0]
    submit = pd.concat([pd.DataFrame(sam_index), res], axis=1)
    submit.to_csv('19-1-27submit.csv', header=sample.columns, index=False)


if __name__ == '__main__':
    score = conv_network()
    print(score)
